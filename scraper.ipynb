{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "import os\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results = 100\n",
    "columns = ['job_title', 'company_name', 'location', 'summary']\n",
    "joblist_df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8f660fb1f426>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m#appending list of job post info to dataframe at index num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mjoblist_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob_post\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1856\u001b[0m                     \u001b[1;31m# must have conforming columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1858\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot set a row with mismatched columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "for start in range(0, max_results, 10):\n",
    "    page = requests.get('http://www.indeed.com/jobs?q=data%20analyst&l=California&start=' + str(start))\n",
    "    time.sleep(2)  #ensuring at least 2 seconds between page grabs\n",
    "    soup = bs(page.text, \"html.parser\")\n",
    "                    \n",
    "    for div in soup.find_all(name='div', attrs={'class':'job_seen_beacon'}):\n",
    "        #specifying row num for index of job posting in dataframe\n",
    "        num = (len(joblist_df) + 1) \n",
    "        #creating an empty list to hold the data for each posting\n",
    "        job_post = [] \n",
    "        \n",
    "        #grabbing job title\n",
    "        for td in soup.find_all(name='td', attrs={'class':'resultContent'}):\n",
    "            for div in td.find_all(name='div', attrs={'class':'heading4 color-text-primary singleLineTitle tapItem-gutter'}):\n",
    "                for span in div.find_all(name='span'):\n",
    "                    if span.text.strip() != 'new':\n",
    "                        job_post.append(span.text.strip())  \n",
    "    \n",
    "        #grabbing company name\n",
    "        for td in soup.find_all(name='td', attrs={'class':'resultContent'}):\n",
    "            for div in td.find_all(name='div', attrs={'class':'heading6 company_location tapItem-gutter'}):\n",
    "                for span in div.find_all(name='span', attrs={'class':'companyName'}):\n",
    "                    job_post.append(span.text.strip())      \n",
    "    \n",
    "    \n",
    "        #grabbing location\n",
    "        for td in soup.find_all(name='td', attrs={'class':'resultContent'}):\n",
    "            for div in td.find_all(name='div', attrs={'class':'heading6 company_location tapItem-gutter'}):\n",
    "                for div in div.find_all(name='div'):\n",
    "                    job_post.append(div.text.strip())   \n",
    "      \n",
    "        #grabbing summary text\n",
    "        divs = soup.findAll('div', attrs={'class': 'job-snippet'})\n",
    "        for div in divs:\n",
    "            job_post.append(div.text.strip())\n",
    "           \n",
    "        #appending list of job post info to dataframe at index num\n",
    "        joblist_df.loc[num] = job_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving sample_df as a local csv file\n",
    "joblist_df.to_csv(\"sample_df.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst',\n",
       " 'Product Data Analyst',\n",
       " 'Data Analyst I',\n",
       " 'Jr. Data Analyst',\n",
       " 'Data Analyst, Reconciliation',\n",
       " 'Senior Data Analyst',\n",
       " 'Programmer Analyst I/II',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst (Full Time) United States',\n",
       " 'Staff Analyst, Production Data & Analytics',\n",
       " 'Research Data Analyst',\n",
       " 'Sr. Associate Data Analyst',\n",
       " 'Associate Analyst, Data Analytics',\n",
       " 'Data Visualization Analyst',\n",
       " 'DreamWorks Technology - Data Analyst',\n",
       " 'Tetra Tech Inc.',\n",
       " 'Vicious Offroad',\n",
       " 'Computershare',\n",
       " 'Deckers Brands',\n",
       " 'Square',\n",
       " 'FocusKPI Inc.',\n",
       " 'Merced County, CA',\n",
       " 'Hulu',\n",
       " 'Cisco Systems',\n",
       " 'Walt Disney Animation Studios',\n",
       " 'Stanford University',\n",
       " 'Amgen',\n",
       " 'Edwards Lifesciences',\n",
       " 'California State University',\n",
       " 'NBCUniversal',\n",
       " 'Chico, CA',\n",
       " 'Ontario, CA 91764•Temporarily Remote',\n",
       " 'United States•Remote',\n",
       " 'Goleta, CA 93117•Remote',\n",
       " 'San Francisco, CA',\n",
       " 'San Francisco Bay Area, CA',\n",
       " 'Merced, CA 95340',\n",
       " 'Santa Monica, CA',\n",
       " 'San Jose, CA',\n",
       " 'Burbank, CA',\n",
       " 'Stanford, CA',\n",
       " 'Thousand Oaks, CA',\n",
       " 'Irvine, CA',\n",
       " 'San Jose, CA',\n",
       " 'Glendale, CA',\n",
       " 'The successful candidate will have extraordinary attention to minute detail and be responsible for executing and overseeing daily administrative, data entry,…',\n",
       " 'Works with data sources to pull new and existing brand data.\\nArrange product data to display correctly on the website.\\n2 – 4 years of related experience.',\n",
       " '1 year of experience in data analysis or the application of data analytics, preferably within the mortgage servicing industry.\\nPaid time away from work.',\n",
       " 'Analyze data to unearth insights and develop data visualizations to facilitate decision making.\\nCreate data sources in Tableau to support reporting for internal…',\n",
       " 'Translate requirements into applicable data requirements.\\n4+ years of experience solving complex data problems.\\nExperience with Linux/OSX command line and git.',\n",
       " 'The ideal candidate is an intelligent, sharp, detail-oriented, and highly quantitative individual who loves working with and analyzing data.',\n",
       " 'Frequent use of data entry device including repetitive hand and arm motion.\\nAnalyze data, interpret directions, procedures and regulations, and develop…',\n",
       " 'Apply advanced analytics techniques (data mining, data visualization, statistical analysis, machine learning) on large-scale, high-dimensional data to help…',\n",
       " 'Assess the effectiveness and accuracy of new data sources and data gathering techniques.\\nPartner and lead cross-functional teams to realize data relationships…',\n",
       " 'The Studio Analytics team is responsible for developing a strategy and vision for cross-functional and complex data analysis projects.',\n",
       " 'Ability to collect data using a variety of methods, such as data mining and hardcopy or electronic documentation studies, to improve or expand databases.',\n",
       " 'Assist with data discovery for enhancing reports and designing efficient data stores.\\nCollaborate cross-functionally with analysts, engineers, to identify &…',\n",
       " 'Good knowledge and understanding of Edwards policies, procedures and guidelines relevant to data analytics.\\nBuild routine quantitative models and/or tools with…',\n",
       " 'Experience with writing scripts to analyze data and perform data queries, creating reports with quantitative modeling, detail-oriented approach to data…',\n",
       " 'Present data analysis findings and/or translate data into an understandable document or dashboard.\\nStrong SQL with experience in querying large, complex data…']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_title, company_name, location, summary]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
